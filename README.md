# NLP-useful-source
NLP나 ML을 공부하기 위한 자료들입니다.



## NLP를 위한 자료들

|제목|링크|비고|
|------|---|----|
|딥러닝을 이용한 자연어 처리 입문|https://wikidocs.net/book/2155|⭐|
|위클리 npl|https://jiho-ml.com/tag/weekly-nlp/| |
|BERT 톺아보기|http://docs.likejazz.com/bert/#fn:fn-2| |
|Awesome Korean NLP Papers|https://github.com/papower1/Awesome-Korean-NLP-Papers|⭐|
|Dissecting BERT Part 1: The Encoder|https://medium.com/dissecting-bert/dissecting-bert-part-1-d3c3d495cdb3| |
|LaRva 데뷰 2019 - 엄~청 큰 언어 모델 공장 가동기!|https://deview.kr/2019/schedule/291| |
|ChrisMcCormickAI 유튜브 채널 |https://www.youtube.com/watch?v=FKlPCK1uFrc&list=PLam9sigHPGwOBuH4_4fr-XvDbe5uneaf6| |
| |https://www.youtube.com/watch?v=l8ZYCvgGu0o| |
|RoBERTa 논문|https://arxiv.org/abs/1907.11692| |
|ALBERT 논문 / 논문 리뷰|https://arxiv.org/abs/1909.11942| |
|ALBERT 논문 / 논문 리뷰|https://y-rok.github.io/nlp/2019/10/23/albert.html| |
|Huggingface/transformers 라이브러리|https://github.com/huggingface/transformers| |
| |https://huggingface.co/transformers/quicktour.html| |
| |https://huggingface.co/models| |
|한국어 Tokenizer 비교|https://blog.pingpong.us/dialog-bert-tokenizer/| |
|TorchText 전처리 라이브러리 사용법|https://wikidocs.net/65348| |
|GPT-2 설명 / BERT랑 비교|http://jalammar.github.io/illustrated-gpt2/| |



## 그 외의 ML에 대한 자료들
|제목|링크|비고|
|--|--|--|
|딥러닝 드리즐|https://deep-learning-drizzle.github.io/|⭐|
|골빈해커의 3분 딥러닝|https://github.com/golbin/TensorFlow-Tutorials| |
|개앞맵시 ML 교재 추천|https://www.mindmeister.com/ko/812276967/_# | |
|텐서플로우 예시들|https://github.com/aymericdamien/TensorFlow-Examples| |
|Stanford Machine Learning|http://www.holehouse.org/mlclass/| |
|coursera 강의|https://www.coursera.org/learn/machine-learning|⭐|
|arxiv|https://arxiv.org/| |


